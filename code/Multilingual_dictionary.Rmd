---
title: "Equivalent_data_selection"
author: "Fabienne Lind"
date: "2024-04-20"
output: html_document
---

# Automated Article Selection and Validation

### Data

In this tasks, we will create and validate search strings for different languages and cases.
I pre-selected data in three language for multiple outlets by using a very broad search string. It included only one keyword per language: 

en: "climate"
de: "klima"
fr: "climatique"

Such a broadly defined search string allows to validate a more specific search string. 
Let's load the data first and take a look. Each row represents one news article.

```{r}

articles <- read.csv("https://raw.githubusercontent.com/fabiennelind/Going-Cross-Lingual_Course/main/data/climate_news.csv")

```

Before we search keyword in the text, we apply some pre-processing steps to the text. For this exercise, we will design the keywords all in lower case, so the texts have to be lower case too.

```{r}

articles$text <- tolower(articles$text) # convert text to lower case

```


The data includes data for several countries. Select at least subsets according to your comparative research question.

```{r}

colnames(articles)
table(articles$Country)
table(articles$Language)

articles_switzerland_de <- subset(articles, Country == "Switzerland" & Language == "de")
articles_switzerland_fr <- subset(articles, Country == "Switzerland" & Language == "fr")
articles_uk_en <- subset(articles, Country == "UK")
articles_austria_de <- subset(articles, Country == "Austria" & Language == "de")
articles_germany_de <- subset(articles, Country == "Germany" & Language == "de")

```

## Automated Data Selection with a Search String per Language

From our universe of articles (all mentioning climate) we like to select only those articles that address climate activism. As a first step, we define the concept more narrowly.

### Concept Definition

**Climate activism** is here defined as mobilization of politically engaged participants—and other stakeholders to address climate challenges 

We intend to measure the salience of climate activism as simple binary variable:
1 = Climate activism is mentioned
0 = No climate activism is mentioned.

### Search string creation

A search string is a set of keywords or phrases that represents the concept of interest. 

We now start collecting relevant keywords for the search strings. We start with a list of keywords that we consider most relevant. 
For clarity, we here work with several keyword sets: we collect the keywords related to country A in two vectors (here named `climate_act_A_de` & `climate_act_A_fr`), and keywords related to  country B in another vector (here named `climate_act_B_en`). 

The keywords are written as regular expressions. A ‘regular expression’ is a pattern that describes a string. To learn more about regular expressions, we recommend this R tutorial [(Wickham & Grolemund, 2017)](https://r4ds.had.co.nz/strings.html). To test regular expressions quickly, visit https://spannbaueradam.shinyapps.io/r_regex_tester/

The following code is only for illustration. Add and modify according to your definition.

```{r}

# German for Switzerland
climate_act_A_de <- c("klimaprotest", "aktivisten")

# French for Switzerland
climate_act_A_fr <- c("protestation climatique", "activistes")

# English for UK
climate_act_B_en <- c("climate protest", "activists", "greta", "fridays for future")

# German for Austria
climate_act_C_de <- c("klimaprotest", "aktivisten")

# German for Germany
climate_act_D_de <- c("klimaprotest", "aktivisten", "luisa neubauer")


```


We now search the keywords in the article texts. The function `stri_count_regex` from the R package **stringr** can count how often a pattern appears in a text. We call this here the number of hits. The function can search for regular expression. We here ask to count a pattern in the column `text` of the dataframe `articles_uk_en`. 

We now first define a function to count keywords in a text

```{r}

library(stringi)
count_keywords <- function(text, keywords) {
  keyword_counts <- sapply(keywords, function(keyword) {
    pattern <- paste0("(?i)", keyword, "\\b") 
        keyword_count <- stri_count_regex(text, pattern)
    return(keyword_count)
  })
  return(keyword_counts)
}

```


Count keywords for each country/language combi and create new columns


```{r}

articles_switzerland_de$climate_activism_count <- apply(articles_switzerland_de, 1, function(row) sum(count_keywords(row["text"], climate_act_A_de)))

articles_switzerland_fr$climate_activism_count <- apply(articles_switzerland_fr, 1, function(row) sum(count_keywords(row["text"], climate_act_A_fr)))

articles_uk_en$climate_activism_count <- apply(articles_uk_en, 1, function(row) sum(count_keywords(row["text"], climate_act_B_en)))

articles_austria_de$climate_activism_count <- apply(articles_austria_de, 1, function(row) sum(count_keywords(row["text"], climate_act_C_de)))

articles_germany_de$climate_activism_count <- apply(articles_germany_de, 1, function(row) sum(count_keywords(row["text"], climate_act_D_de)))

articles_anno <- rbind(articles_switzerland_de, articles_switzerland_fr, articles_uk_en, articles_austria_de, articles_germany_de)

```

Function to check which keywords were found and concatenate them

```{r}

check_keywords <- function(text, keywords) {
  found_keywords <- keywords[stri_detect_regex(text, paste0("(?i)\\b", keywords, "\\b"))]
  return(paste(found_keywords, collapse = ", "))
}

```

Check which keywords were found for each group for each row and create a single column

```{r}

articles_switzerland_de$climate_act_keywords_found <- apply(articles_switzerland_de, 1, function(row) check_keywords(row["text"], climate_act_A_de))

articles_switzerland_fr$climate_act_keywords_found <- apply(articles_switzerland_fr, 1, function(row) check_keywords(row["text"], climate_act_A_fr))

articles_uk_en$climate_act_keywords_found <- apply(articles_uk_en, 1, function(row) check_keywords(row["text"], climate_act_B_en))

articles_austria_de$climate_act_keywords_found <- apply(articles_austria_de, 1, function(row) check_keywords(row["text"], climate_act_C_de))

articles_germany_de$climate_act_keywords_found <- apply(articles_germany_de, 1, function(row) check_keywords(row["text"], climate_act_D_de))



table(articles_switzerland_de$climate_act_keywords_found)
table(articles_switzerland_fr$climate_act_keywords_found)
table(articles_uk_en$climate_act_keywords_found)
table(articles_austria_de$climate_act_keywords_found)
table(articles_germany_de$climate_act_keywords_found)


```

So far, we obtained a count, that represents how often the keywords were detected per text. Since we initially proposed a simple binary measurement, we now do some recoding. 

We add a new column to the dataframe called `climate_activism`. This column includes a 1 if at least one of all defined keywords creates a hit, and a 0 if no keyword was found. 

```{r}

library(dplyr)
articles_anno$climate_activism <- case_when(articles_anno$climate_activism_count >= 1  ~ 1)# | means or. 
articles_anno <- articles_anno %>% mutate(climate_activism = if_else(is.na(climate_activism), 0, climate_activism)) # set NA to 0 



```

According to our automated measurement, how many articles deal with climate activism for all cases?

```{r}

table(articles_anno$climate_activism) # descriptive overview

```

How many deal with climate activism per case?

```{r}

#calc total number of articles per country

articles_anno$num <- 1

total <- articles_anno %>%
  group_by(Country)  %>%
  summarize(total = sum(num))

V1 <- articles_anno %>%
  group_by(Country)  %>%
  summarize(climate_activism_frequency = sum(climate_activism))

V1 <- subset(V1, select = -c(Country))

data_agg <- cbind(total, V1)

#calc relative frequency (based on the total coverage per country)       
data_agg$climate_activism_rel <- data_agg$total/data_agg$climate_activism_frequency

```

```{r}

# Plotting histogram
library(ggplot2)
ggplot(data_agg, aes(x = Country, y = climate_activism_rel, fill = Country)) +
  geom_bar(stat = "identity") +
  labs(x = "Country", y = "Relative Frequency", title = "Salience of Climate Activism in Climate Change Coverage by Country") +
  theme_minimal()
```


Let's save the result

```{r}

setwd("")
write.csv(articles_anno, "climate_news_d_annotated.csv", row.names = F)

```

We have now managed to get an automated measurement for the variable. **But how valid is this measurement?** Does our small set of keywords represent the concept adequately?

A common procedure in automated content analysis is to test construct validity. We ask:
How close is this automated measurement to a more trusted measurement: Human understanding of text.

We will see how this can be put into practice when we discuss output evaluation. 



